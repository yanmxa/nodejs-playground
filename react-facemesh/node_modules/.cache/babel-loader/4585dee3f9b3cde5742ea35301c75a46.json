{"ast":null,"code":"import { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nvar _jsxFileName = \"/Users/yanmeng/workspace/react/react-tensorflow/src/App.js\",\n    _s = $RefreshSig$();\n\nimport logo from \"./logo.svg\";\nimport \"./App.css\";\nimport React, { useRef } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as facemesh from \"@tensorflow-models/facemesh\";\nimport Webcam from \"react-webcam\";\n\nfunction App() {\n  _s();\n\n  // Setup references\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null); // Load facemesh\n\n  const runFacemesh = async () => {\n    const net = await facemesh.load({\n      inputResolution: {\n        width: 640,\n        height: 480\n      },\n      scale: 0.8\n    });\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  }; // Detect function\n\n\n  const detect = async net => {\n    if (typeof webcamRef.current !== \"undefined\" && webcamRef.current !== null && webcamRef.current.video.readyState === 4) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight; // Set Video Width\n\n      webcamRef.current.width = videoWidth;\n      webcamRef.current.height = videoHeight; // Set Canvas Width\n\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight; // Make detections\n\n      const face = await net.estimateFaces(video); // Get canvas context for drawing\n    }\n  };\n\n  runFacemesh();\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: [/*#__PURE__*/_jsxDEV(Webcam, {\n        ref: webcamRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zIndex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 56,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"canvas\", {\n        ref: canvasRef,\n        style: {\n          position: \"absolute\",\n          marginLeft: \"auto\",\n          marginRight: \"auto\",\n          left: 0,\n          right: 0,\n          textAlign: \"center\",\n          zIndex: 9,\n          width: 640,\n          height: 480\n        }\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 70,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 55,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 54,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"AwQWgsmsPhWgADiRou0jnDEtoH4=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/yanmeng/workspace/react/react-tensorflow/src/App.js"],"names":["React","useRef","tf","facemesh","Webcam","App","webcamRef","canvasRef","runFacemesh","net","load","inputResolution","width","height","scale","setInterval","detect","current","video","readyState","videoWidth","videoHeight","face","estimateFaces","position","marginLeft","marginRight","left","right","textAlign","zIndex"],"mappings":";;;;;;AACA,OAAO,WAAP;AAEA,OAAOA,KAAP,IAAgBC,MAAhB,QAA8B,OAA9B;AACA,OAAO,KAAKC,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,QAAZ,MAA0B,6BAA1B;AACA,OAAOC,MAAP,MAAmB,cAAnB;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb;AACA,QAAMC,SAAS,GAAGL,MAAM,CAAC,IAAD,CAAxB;AACA,QAAMM,SAAS,GAAGN,MAAM,CAAC,IAAD,CAAxB,CAHa,CAKb;;AACA,QAAMO,WAAW,GAAG,YAAY;AAC9B,UAAMC,GAAG,GAAG,MAAMN,QAAQ,CAACO,IAAT,CAAc;AAC9BC,MAAAA,eAAe,EAAE;AAAEC,QAAAA,KAAK,EAAE,GAAT;AAAcC,QAAAA,MAAM,EAAE;AAAtB,OADa;AAE9BC,MAAAA,KAAK,EAAE;AAFuB,KAAd,CAAlB;AAIAC,IAAAA,WAAW,CAAC,MAAM;AAChBC,MAAAA,MAAM,CAACP,GAAD,CAAN;AACD,KAFU,EAER,GAFQ,CAAX;AAGD,GARD,CANa,CAgBb;;;AACA,QAAMO,MAAM,GAAG,MAAOP,GAAP,IAAe;AAC5B,QACE,OAAOH,SAAS,CAACW,OAAjB,KAA6B,WAA7B,IACAX,SAAS,CAACW,OAAV,KAAsB,IADtB,IAEAX,SAAS,CAACW,OAAV,CAAkBC,KAAlB,CAAwBC,UAAxB,KAAuC,CAHzC,EAIE;AACA;AACA,YAAMD,KAAK,GAAGZ,SAAS,CAACW,OAAV,CAAkBC,KAAhC;AACA,YAAME,UAAU,GAAGd,SAAS,CAACW,OAAV,CAAkBC,KAAlB,CAAwBE,UAA3C;AACA,YAAMC,WAAW,GAAGf,SAAS,CAACW,OAAV,CAAkBC,KAAlB,CAAwBG,WAA5C,CAJA,CAMA;;AACAf,MAAAA,SAAS,CAACW,OAAV,CAAkBL,KAAlB,GAA0BQ,UAA1B;AACAd,MAAAA,SAAS,CAACW,OAAV,CAAkBJ,MAAlB,GAA2BQ,WAA3B,CARA,CAUA;;AACAd,MAAAA,SAAS,CAACU,OAAV,CAAkBL,KAAlB,GAA0BQ,UAA1B;AACAb,MAAAA,SAAS,CAACU,OAAV,CAAkBJ,MAAlB,GAA2BQ,WAA3B,CAZA,CAcA;;AACA,YAAMC,IAAI,GAAG,MAAMb,GAAG,CAACc,aAAJ,CAAkBL,KAAlB,CAAnB,CAfA,CAgBA;AACD;AACF,GAvBD;;AAyBAV,EAAAA,WAAW;AAEX,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,2BACE;AAAQ,MAAA,SAAS,EAAC,YAAlB;AAAA,8BACE,QAAC,MAAD;AACE,QAAA,GAAG,EAAEF,SADP;AAEE,QAAA,KAAK,EAAE;AACLkB,UAAAA,QAAQ,EAAE,UADL;AAELC,UAAAA,UAAU,EAAE,MAFP;AAGLC,UAAAA,WAAW,EAAE,MAHR;AAILC,UAAAA,IAAI,EAAE,CAJD;AAKLC,UAAAA,KAAK,EAAE,CALF;AAMLC,UAAAA,SAAS,EAAE,QANN;AAOLC,UAAAA,MAAM,EAAE,CAPH;AAQLlB,UAAAA,KAAK,EAAE,GARF;AASLC,UAAAA,MAAM,EAAE;AATH;AAFT;AAAA;AAAA;AAAA;AAAA,cADF,eAeE;AACE,QAAA,GAAG,EAAEN,SADP;AAEE,QAAA,KAAK,EAAE;AACLiB,UAAAA,QAAQ,EAAE,UADL;AAELC,UAAAA,UAAU,EAAE,MAFP;AAGLC,UAAAA,WAAW,EAAE,MAHR;AAILC,UAAAA,IAAI,EAAE,CAJD;AAKLC,UAAAA,KAAK,EAAE,CALF;AAMLC,UAAAA,SAAS,EAAE,QANN;AAOLC,UAAAA,MAAM,EAAE,CAPH;AAQLlB,UAAAA,KAAK,EAAE,GARF;AASLC,UAAAA,MAAM,EAAE;AATH;AAFT;AAAA;AAAA;AAAA;AAAA,cAfF;AAAA;AAAA;AAAA;AAAA;AAAA;AADF;AAAA;AAAA;AAAA;AAAA,UADF;AAkCD;;GA9EQR,G;;KAAAA,G;AAgFT,eAAeA,GAAf","sourcesContent":["import logo from \"./logo.svg\";\nimport \"./App.css\";\n\nimport React, { useRef } from \"react\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as facemesh from \"@tensorflow-models/facemesh\";\nimport Webcam from \"react-webcam\";\n\nfunction App() {\n  // Setup references\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  // Load facemesh\n  const runFacemesh = async () => {\n    const net = await facemesh.load({\n      inputResolution: { width: 640, height: 480 },\n      scale: 0.8,\n    });\n    setInterval(() => {\n      detect(net);\n    }, 100);\n  };\n\n  // Detect function\n  const detect = async (net) => {\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set Video Width\n      webcamRef.current.width = videoWidth;\n      webcamRef.current.height = videoHeight;\n\n      // Set Canvas Width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // Make detections\n      const face = await net.estimateFaces(video);\n      // Get canvas context for drawing\n    }\n  };\n\n  runFacemesh();\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zIndex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zIndex: 9,\n            width: 640,\n            height: 480,\n          }}\n        ></canvas>\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}